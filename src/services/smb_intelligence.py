#!/usr/bin/env python3
"""
SMB Intelligence Platform - Complete Implementation
Run this single file to start your SMB intelligence service
"""

import pandas as pd
import asyncio
import sqlite3
import json
from datetime import datetime
from typing import Dict, List, Optional
from dataclasses import dataclass
import hashlib
import sys
import os

# FastAPI imports
from fastapi import FastAPI, HTTPException, Query
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from enum import Enum
import uvicorn

# Check if running as main script vs imported
IS_MAIN = __name__ == "__main__"

# ==================== DATA MODELS ====================

@dataclass
class EnrichedSMB:
    """Enhanced SMB data structure with enrichment fields"""
    organization_name: str
    uei: str
    email: str
    state: str
    naics_code: str
    google_reviews_rating: Optional[float] = None
    google_reviews_count: Optional[int] = None
    linkedin_company_url: Optional[str] = None
    owner_linkedin_url: Optional[str] = None
    estimated_revenue: Optional[float] = None
    employee_count: Optional[int] = None
    years_in_business: Optional[int] = None
    succession_risk_score: Optional[float] = None
    digital_presence_score: Optional[float] = None
    last_enriched: Optional[datetime] = None

# ==================== ENRICHMENT PIPELINE ====================

class SMBEnrichmentPipeline:
    """Main enrichment pipeline for SMB data"""
    
    def __init__(self, db_path: str = "smb_intelligence.db"):
        self.db_path = db_path
        self._init_database()
        
    def _init_database(self):
        """Initialize SQLite database for enriched data"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS enriched_smbs (
                uei TEXT PRIMARY KEY,
                organization_name TEXT NOT NULL,
                email TEXT,
                state TEXT,
                naics_code TEXT,
                google_reviews_rating REAL,
                google_reviews_count INTEGER,
                linkedin_company_url TEXT,
                owner_linkedin_url TEXT,
                estimated_revenue REAL,
                employee_count INTEGER,
                years_in_business INTEGER,
                succession_risk_score REAL,
                digital_presence_score REAL,
                last_enriched TIMESTAMP,
                raw_data JSON
            )
        ''')
        
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_state ON enriched_smbs(state)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_naics ON enriched_smbs(naics_code)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_succession_risk ON enriched_smbs(succession_risk_score)')
        
        conn.commit()
        conn.close()
    
    async def enrich_batch(self, smbs: List[Dict], batch_size: int = 100):
        """Enrich a batch of SMBs with external data"""
        print(f"Starting enrichment of {len(smbs)} SMBs...")
        
        for i in range(0, len(smbs), batch_size):
            batch = smbs[i:i+batch_size]
            enriched_results = []
            
            for smb in batch:
                enriched = await self._enrich_single_smb(smb)
                enriched_results.append(enriched)
            
            self._save_batch(enriched_results)
            print(f"Enriched {i+len(batch)}/{len(smbs)} SMBs")
    
    async def _enrich_single_smb(self, smb: Dict) -> EnrichedSMB:
        """Enrich a single SMB with all available data sources"""
        enriched = EnrichedSMB(
            organization_name=smb.get('Organization Name', ''),
            uei=smb.get('UEI (Unique Entity Identifier)', f"UEI-{hash(smb.get('Organization Name', ''))}"),
            email=smb.get('Email', ''),
            state=smb.get('State', ''),
            naics_code=str(smb.get('Primary NAICS code', ''))
        )
        
        # Simulate enrichment
        await self._fetch_google_reviews(enriched)
        await self._estimate_revenue(enriched)
        await self._calculate_digital_presence(enriched)
        await self._calculate_succession_risk(enriched, smb)
        
        enriched.last_enriched = datetime.now()
        return enriched
    
    async def _fetch_google_reviews(self, smb: EnrichedSMB):
        """Simulate Google Reviews data"""
        if smb.state in ['California', 'New York', 'Texas', 'Florida']:
            smb.google_reviews_rating = 4.2 + (hash(smb.organization_name) % 8) / 10
            smb.google_reviews_count = 50 + (hash(smb.organization_name) % 200)
        else:
            smb.google_reviews_rating = 3.8 + (hash(smb.organization_name) % 12) / 10
            smb.google_reviews_count = 10 + (hash(smb.organization_name) % 50)
    
    async def _estimate_revenue(self, smb: EnrichedSMB):
        """Estimate revenue based on NAICS code and other factors"""
        naics_revenue_map = {
            '23': 2500000,  # Construction
            '31': 5000000,  # Manufacturing
            '42': 3000000,  # Wholesale Trade
            '44': 1500000,  # Retail Trade
            '54': 1000000,  # Professional Services
            '72': 800000,   # Accommodation and Food
        }
        
        naics_prefix = smb.naics_code[:2] if smb.naics_code else '00'
        base_revenue = naics_revenue_map.get(naics_prefix, 1000000)
        
        state_multiplier = {
            'California': 1.5,
            'New York': 1.4,
            'Texas': 1.3,
            'Florida': 1.2
        }.get(smb.state, 1.0)
        
        smb.estimated_revenue = base_revenue * state_multiplier
        smb.employee_count = int(smb.estimated_revenue / 150000)
    
    async def _calculate_digital_presence(self, smb: EnrichedSMB):
        """Calculate digital presence score"""
        score = 0.0
        
        if smb.email and '@' in smb.email:
            score += 2.0
        
        if smb.google_reviews_count:
            if smb.google_reviews_count > 100:
                score += 3.0
            elif smb.google_reviews_count > 50:
                score += 2.0
            else:
                score += 1.0
        
        if smb.google_reviews_rating and smb.google_reviews_rating > 4.0:
            score += 2.0
        
        smb.digital_presence_score = min(score, 10.0)
    
    async def _calculate_succession_risk(self, smb: EnrichedSMB, original_data: Dict):
        """Calculate succession risk score (0-10, higher = more risk)"""
        risk_score = 5.0
        
        high_risk_industries = ['238', '236', '811', '812']
        if any(smb.naics_code.startswith(ind) for ind in high_risk_industries):
            risk_score += 2.0
        
        if smb.employee_count and smb.employee_count < 10:
            risk_score += 1.5
        
        if original_data.get('Legal structure') == 'Sole Proprietorship':
            risk_score += 2.0
        
        if smb.digital_presence_score and smb.digital_presence_score < 3.0:
            risk_score += 1.0
        
        if 'SDVOSB' in str(original_data.get('Active SBA certifications', '')):
            risk_score += 0.5
        
        smb.succession_risk_score = min(risk_score, 10.0)
    
    def _save_batch(self, enriched_smbs: List[EnrichedSMB]):
        """Save enriched SMBs to database"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        for smb in enriched_smbs:
            cursor.execute('''
                INSERT OR REPLACE INTO enriched_smbs VALUES (
                    ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?
                )
            ''', (
                smb.uei,
                smb.organization_name,
                smb.email,
                smb.state,
                smb.naics_code,
                smb.google_reviews_rating,
                smb.google_reviews_count,
                smb.linkedin_company_url,
                smb.owner_linkedin_url,
                smb.estimated_revenue,
                smb.employee_count,
                smb.years_in_business,
                smb.succession_risk_score,
                smb.digital_presence_score,
                smb.last_enriched,
                json.dumps(smb.__dict__, default=str)
            ))
        
        conn.commit()
        conn.close()

# ==================== API SERVICE ====================

# FastAPI app
app = FastAPI(
    title="SMB Intelligence API",
    description="Predictive intelligence platform for SMB wealth transfer",
    version="1.0.0"
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# API Models
class RiskLevel(str, Enum):
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"

class SMBSummary(BaseModel):
    uei: str
    organization_name: str
    state: str
    naics_code: str
    succession_risk_score: float
    estimated_revenue: float
    employee_count: int
    digital_presence_score: float
    risk_level: RiskLevel

class SuccessionRiskAnalysis(BaseModel):
    total_businesses: int
    high_risk_count: int
    critical_risk_count: int
    total_estimated_value: float
    average_risk_score: float
    risk_distribution: Dict[str, int]
    top_risk_factors: List[str]
    businesses: List[SMBSummary]

# API Endpoints
@app.get("/")
def root():
    return {
        "message": "SMB Intelligence API",
        "documentation": "/docs",
        "endpoints": {
            "succession_risk": "/api/intelligence/succession-risk",
            "business_search": "/api/businesses/search",
        }
    }

@app.get("/api/intelligence/succession-risk", response_model=SuccessionRiskAnalysis)
def get_succession_risk(
    state: Optional[str] = Query(None, description="Filter by state"),
    limit: int = Query(100, description="Maximum number of results")
):
    """Get succession risk analysis for businesses"""
    conn = sqlite3.connect("smb_intelligence.db")
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()
    
    query = "SELECT * FROM enriched_smbs WHERE 1=1"
    params = []
    
    if state:
        query += " AND state = ?"
        params.append(state)
    
    cursor.execute(query, params)
    all_results = cursor.fetchall()
    
    if not all_results:
        return SuccessionRiskAnalysis(
            total_businesses=0,
            high_risk_count=0,
            critical_risk_count=0,
            total_estimated_value=0,
            average_risk_score=0,
            risk_distribution={"low": 0, "medium": 0, "high": 0, "critical": 0},
            top_risk_factors=[],
            businesses=[]
        )
    
    # Calculate statistics
    total_businesses = len(all_results)
    high_risk_count = sum(1 for r in all_results if r['succession_risk_score'] >= 7)
    critical_risk_count = sum(1 for r in all_results if r['succession_risk_score'] >= 9)
    total_value = sum(r['estimated_revenue'] or 0 for r in all_results)
    avg_risk = sum(r['succession_risk_score'] or 0 for r in all_results) / total_businesses
    
    risk_dist = {
        "low": sum(1 for r in all_results if r['succession_risk_score'] < 4),
        "medium": sum(1 for r in all_results if 4 <= r['succession_risk_score'] < 7),
        "high": sum(1 for r in all_results if 7 <= r['succession_risk_score'] < 9),
        "critical": sum(1 for r in all_results if r['succession_risk_score'] >= 9)
    }
    
    # Get top businesses
    query += " ORDER BY succession_risk_score DESC LIMIT ?"
    params.append(limit)
    
    cursor.execute(query, params)
    businesses = []
    
    for row in cursor.fetchall():
        risk_score = row['succession_risk_score'] or 0
        if risk_score < 4:
            risk_level = RiskLevel.LOW
        elif risk_score < 7:
            risk_level = RiskLevel.MEDIUM
        elif risk_score < 9:
            risk_level = RiskLevel.HIGH
        else:
            risk_level = RiskLevel.CRITICAL
        
        businesses.append(SMBSummary(
            uei=row['uei'],
            organization_name=row['organization_name'],
            state=row['state'],
            naics_code=row['naics_code'],
            succession_risk_score=risk_score,
            estimated_revenue=row['estimated_revenue'] or 0,
            employee_count=row['employee_count'] or 0,
            digital_presence_score=row['digital_presence_score'] or 0,
            risk_level=risk_level
        ))
    
    conn.close()
    
    return SuccessionRiskAnalysis(
        total_businesses=total_businesses,
        high_risk_count=high_risk_count,
        critical_risk_count=critical_risk_count,
        total_estimated_value=total_value,
        average_risk_score=avg_risk,
        risk_distribution=risk_dist,
        top_risk_factors=[
            "Owner age above 60",
            "No identified successor",
            "Sole proprietorship structure",
            "Limited digital presence",
            "Industry consolidation trends"
        ],
        businesses=businesses
    )

# ==================== MAIN EXECUTION ====================

async def enrich_data():
    """Load and enrich SMB data"""
    print("\nüöÄ Starting SMB Intelligence Platform Setup...")
    
    # Look for CSV files in multiple locations
    csv_files = []
    
    # Check data/dsbs_raw directory first
    if os.path.exists('data/dsbs_raw/All_DSBS_processed_chunk_full_20250728.csv'):
        csv_files = ['data/dsbs_raw/All_DSBS_processed_chunk_full_20250728.csv']
        print("‚úÖ Found full dataset in data/dsbs_raw/")
    # Check data directory
    elif os.path.exists('data/All_DSBS_processed_chunk_001_20250727_182259.csv'):
        csv_files = ['data/All_DSBS_processed_chunk_001_20250727_182259.csv']
        print("‚úÖ Found dataset in data/")
    # Check current directory for chunk files
    else:
        csv_files = [f for f in os.listdir('.') if f.startswith('All_DSBS_processed_chunk') and f.endswith('.csv')]
    
    if not csv_files:
        print("\n‚ö†Ô∏è  No DSBS CSV files found!")
        print("Please ensure your CSV files are in one of these locations:")
        print("  - data/dsbs_raw/All_DSBS_processed_chunk_full_20250728.csv")
        print("  - data/All_DSBS_processed_chunk_001_20250727_182259.csv")
        print("  - ./All_DSBS_processed_chunk_*.csv")
        return False
    
    print(f"\nüìÅ Found {len(csv_files)} CSV file(s)")
    
    # Load data
    all_data = []
    for file in csv_files:
        print(f"Loading {file}...")
        try:
            df = pd.read_csv(file)
            all_data.extend(df.to_dict('records'))
            print(f"  ‚úÖ Loaded {len(df)} records from {file}")
        except Exception as e:
            print(f"  ‚ùå Error loading {file}: {e}")
    
    print(f"\nüìä Loaded {len(all_data)} total SMB records")
    
    # Initialize pipeline
    pipeline = SMBEnrichmentPipeline()
    
    # Determine sample size
    if len(all_data) > 10000:
        print(f"\nüîÑ Large dataset detected. Processing in batches...")
        # For large datasets, process in chunks to avoid memory issues
        sample_size = len(all_data)
    else:
        sample_size = len(all_data)
    
    print(f"\nüîÑ Enriching {sample_size} records...")
    
    await pipeline.enrich_batch(all_data[:sample_size])
    
    print("\n‚úÖ Data enrichment complete!")
    
    # Show summary statistics
    conn = sqlite3.connect("smb_intelligence.db")
    cursor = conn.cursor()
    cursor.execute("SELECT COUNT(*) FROM enriched_smbs")
    total = cursor.fetchone()[0]
    
    cursor.execute("SELECT COUNT(*) FROM enriched_smbs WHERE succession_risk_score >= 7")
    high_risk = cursor.fetchone()[0]
    
    cursor.execute("SELECT state, COUNT(*) as count FROM enriched_smbs GROUP BY state ORDER BY count DESC LIMIT 5")
    top_states = cursor.fetchall()
    
    conn.close()
    
    print(f"\nüìà Summary Statistics:")
    print(f"  - Total businesses enriched: {total:,}")
    print(f"  - High-risk succession opportunities: {high_risk:,}")
    print(f"  - Top states by business count:")
    for state, count in top_states:
        print(f"    ‚Ä¢ {state}: {count:,}")
    
    return True

def start_api():
    """Start the API server"""
    print("\nüåê Starting API server...")
    print("üìñ API Documentation: http://localhost:8000/docs")
    print("üîó Succession Risk Endpoint: http://localhost:8000/api/intelligence/succession-risk")
    print("\nüí° Try: http://localhost:8000/api/intelligence/succession-risk?state=Florida")
    print("\n‚èπÔ∏è  Press CTRL+C to stop the server\n")
    
    uvicorn.run(app, host="0.0.0.0", port=8001)

# Main execution
if IS_MAIN:
    import argparse
    
    parser = argparse.ArgumentParser(description='SMB Intelligence Platform')
    parser.add_argument('--enrich-only', action='store_true', help='Only run data enrichment')
    parser.add_argument('--api-only', action='store_true', help='Only start API server')
    
    args = parser.parse_args()
    
    if args.api_only:
        start_api()
    elif args.enrich_only:
        asyncio.run(enrich_data())
    else:
        # Run both enrichment and API
        if asyncio.run(enrich_data()):
            start_api()
        else:
            print("\n‚ùå Failed to enrich data. Please check your CSV files.")
